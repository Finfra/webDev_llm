// LM Studio ë¡œì»¬ API í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
// ì‚¬ìš© ì „ LM Studioì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  Local Serverë¥¼ ì‹œì‘í•˜ì„¸ìš”

const axios = require('axios');

// LM Studio ê¸°ë³¸ ì„¤ì •
const LM_STUDIO_URL = 'http://localhost:1234';

class LMStudioClient {
    constructor(baseURL = LM_STUDIO_URL) {
        this.baseURL = baseURL;
    }

    // ì„œë²„ ìƒíƒœ í™•ì¸
    async checkStatus() {
        try {
            const response = await axios.get(`${this.baseURL}/v1/models`);
            console.log('âœ… LM Studio ì„œë²„ ì—°ê²° ì„±ê³µ');
            console.log('ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:', response.data.data.map(m => m.id));
            return true;
        } catch (error) {
            console.error('âŒ LM Studio ì„œë²„ ì—°ê²° ì‹¤íŒ¨:', error.message);
            console.log('ğŸ’¡ í•´ê²°ë°©ë²•:');
            console.log('1. LM Studioê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸');
            console.log('2. ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸');
            console.log('3. Local Serverê°€ ì‹œì‘ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸');
            return false;
        }
    }

    // í…ìŠ¤íŠ¸ ìƒì„± (ì™„ì„±)
    async generateCompletion(prompt, options = {}) {
        try {
            const response = await axios.post(`${this.baseURL}/v1/completions`, {
                prompt: prompt,
                max_tokens: options.max_tokens || 100,
                temperature: options.temperature || 0.7,
                top_p: options.top_p || 0.9,
                stream: false
            });

            return response.data.choices[0].text;
        } catch (error) {
            console.error('í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨:', error.message);
            throw error;
        }
    }

    // ì±„íŒ… í˜•ì‹ ëŒ€í™”
    async generateChatCompletion(messages, options = {}) {
        try {
            const response = await axios.post(`${this.baseURL}/v1/chat/completions`, {
                model: 'local-model', // LM StudioëŠ” 'local-model' ì‚¬ìš©
                messages: messages,
                max_tokens: options.max_tokens || 150,
                temperature: options.temperature || 0.7,
                stream: false
            });

            return response.data.choices[0].message.content;
        } catch (error) {
            console.error('ì±„íŒ… ìƒì„± ì‹¤íŒ¨:', error.message);
            throw error;
        }
    }

    // ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (ì‹¤ì‹œê°„)
    async generateStreamingChat(messages, onChunk, options = {}) {
        try {
            const response = await axios.post(`${this.baseURL}/v1/chat/completions`, {
                model: 'local-model',
                messages: messages,
                max_tokens: options.max_tokens || 150,
                temperature: options.temperature || 0.7,
                stream: true
            }, {
                responseType: 'stream'
            });

            return new Promise((resolve, reject) => {
                let fullResponse = '';
                
                response.data.on('data', (chunk) => {
                    const lines = chunk.toString().split('\n').filter(line => line.trim());
                    
                    for (const line of lines) {
                        if (line.startsWith('data: ')) {
                            const data = line.slice(6);
                            if (data === '[DONE]') {
                                resolve(fullResponse);
                                return;
                            }
                            
                            try {
                                const parsed = JSON.parse(data);
                                const content = parsed.choices[0]?.delta?.content || '';
                                if (content) {
                                    fullResponse += content;
                                    onChunk(content);
                                }
                            } catch (e) {
                                // JSON íŒŒì‹± ì˜¤ë¥˜ ë¬´ì‹œ
                            }
                        }
                    }
                });

                response.data.on('error', reject);
            });
        } catch (error) {
            console.error('ìŠ¤íŠ¸ë¦¬ë° ìƒì„± ì‹¤íŒ¨:', error.message);
            throw error;
        }
    }
}

// í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
async function testBasicCompletion() {
    console.log('\nğŸ§ª ê¸°ë³¸ í…ìŠ¤íŠ¸ ì™„ì„± í…ŒìŠ¤íŠ¸');
    console.log('='.repeat(50));
    
    const client = new LMStudioClient();
    
    try {
        const result = await client.generateCompletion(
            "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ í•œêµ­ì–´ë¡œ ê°„ë‹¨íˆ ì„¤ëª…í•˜ë©´",
            { max_tokens: 100, temperature: 0.7 }
        );
        
        console.log('ğŸ’¬ ìƒì„±ëœ í…ìŠ¤íŠ¸:');
        console.log(result);
    } catch (error) {
        console.error('í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error.message);
    }
}

async function testChatCompletion() {
    console.log('\nğŸ§ª ì±„íŒ… ëŒ€í™” í…ŒìŠ¤íŠ¸');
    console.log('='.repeat(50));
    
    const client = new LMStudioClient();
    
    const messages = [
        { role: "system", content: "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”." },
        { role: "user", content: "íŒŒì´ì¬ìœ¼ë¡œ í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ì„ êµ¬í•˜ëŠ” ê°„ë‹¨í•œ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”." }
    ];
    
    try {
        const result = await client.generateChatCompletion(messages, {
            max_tokens: 200,
            temperature: 0.3
        });
        
        console.log('ğŸ¤– AI ì‘ë‹µ:');
        console.log(result);
    } catch (error) {
        console.error('í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error.message);
    }
}

async function testStreamingChat() {
    console.log('\nğŸ§ª ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í…ŒìŠ¤íŠ¸');
    console.log('='.repeat(50));
    
    const client = new LMStudioClient();
    
    const messages = [
        { role: "system", content: "ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ê¸€ì“°ê¸° ë„ìš°ë¯¸ì…ë‹ˆë‹¤." },
        { role: "user", content: "ìš°ì£¼ ì—¬í–‰ì— ëŒ€í•œ ì§§ì€ ì‹œë¥¼ í•œêµ­ì–´ë¡œ ì¨ì£¼ì„¸ìš”." }
    ];
    
    try {
        console.log('ğŸ¤– AI ì‘ë‹µ (ì‹¤ì‹œê°„):');
        process.stdout.write('ğŸ’­ ');
        
        await client.generateStreamingChat(messages, (chunk) => {
            process.stdout.write(chunk);
        }, {
            max_tokens: 150,
            temperature: 0.8
        });
        
        console.log('\nâœ… ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ');
    } catch (error) {
        console.error('í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error.message);
    }
}

// ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
async function runAllTests() {
    console.log('ğŸš€ LM Studio API í…ŒìŠ¤íŠ¸ ì‹œì‘');
    console.log('='.repeat(50));
    
    const client = new LMStudioClient();
    
    // ì„œë²„ ìƒíƒœ í™•ì¸
    const isConnected = await client.checkStatus();
    if (!isConnected) {
        return;
    }
    
    // ê° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    await testBasicCompletion();
    await testChatCompletion();
    await testStreamingChat();
    
    console.log('\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!');
}

// ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if (require.main === module) {
    // axios ì„¤ì¹˜ í™•ì¸
    try {
        require('axios');
    } catch (error) {
        console.error('âŒ axios íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
        console.log('ğŸ’¡ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: npm install axios');
        process.exit(1);
    }
    
    runAllTests().catch(console.error);
}

module.exports = { LMStudioClient };
